{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Amisha Meka\n",
        "\n",
        "Assignment Week 09 - Machine Leanrning with Scikit Learn"
      ],
      "metadata": {
        "id": "gTgBsGDaTWYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.**\n",
        "\n",
        "Several machine learning models were assessed in the results table of the notebook to forecast patient mortality. The RandomForest_CV2 model demonstrates the most effective performance based on the analyzed evidence. The model demonstrated a suitable accuracy distribution by reaching 0.7473 training score and 0.736 testing score.\n",
        "The RandomForest_noCV model produced almost perfect results (0.9993) during training but achieved only 0.686 accuracy on testing which indicates severe model overfitting. The training and testing scores show a substantial difference which indicates the model learned training data patterns instead of developing generalizable patterns.\n",
        "All logistic regression models with different penalty parameters including Logistic and Logistic_L1 with multiple C values exhibited similar performance levels by achieving 0.73 average training accuracy as well as test accuracy between 0.71 and 0.72. Testing results match training results very well yet the RandomForest_CV2 maintains slightly better overall performance.\n",
        "The RandomForest_CV2 model reached the highest accuracy level while maintaining optimal generalization capacity through its implementation of grid search cross-validation on maximum depth parameter optimization. The optimization method stopped model overfitting through proper control of tree depth as it sustained high predictive capabilities. The model surpasses the initial RandomForest_noCV through an exchange of training accuracy for better new data performance.\n",
        "The RandomForest_CV2 model demonstrates the best performance because of its 0.736 test accuracy rate and its acceptable difference between training and testing scores which indicates strong generalization abilities."
      ],
      "metadata": {
        "id": "4mGWtSE5ThLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, fit a series of logistic regression models, without regularization. Each model should use the same set of predictors (all of the relevant predictors in the dataset) and should use the entire dataset, rather than a fraction of it. Use a randomly chosen 80% proportion of observations for training and the remaining for checking the generalizable performance (i.e., performance on the holdout subset). Be sure to ensure that the training and holdout subsets are identical across all models. Each model should choose a different solver.**\n",
        "\n",
        "\n",
        "\n",
        "**Compare the results of the models in terms of their accuracy (use this as the performance metric to assess generalizability error on the holdout subset) and the time taken (use appropriate timing function). Summarize your results via a table with the following structure:**"
      ],
      "metadata": {
        "id": "aCOubjYYTnTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChhLsw4ATGXH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from patsy import dmatrices\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patient_data = pd.read_csv('./PatientAnalyticFile.csv')"
      ],
      "metadata": {
        "id": "7QiUQ13HUMbQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_data['mortality'] = np.where(patient_data['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "patient_data['DateOfBirth'] = pd.to_datetime(patient_data['DateOfBirth'])\n",
        "patient_data['Age_years'] = ((pd.to_datetime('2015-01-01') - patient_data['DateOfBirth']).dt.days/365.25)\n",
        "\n",
        "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
        "               'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "vars_left = set(patient_data.columns) - set(vars_remove)\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)"
      ],
      "metadata": {
        "id": "jn3uFNLuUON3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y, X = dmatrices(formula, patient_data)\n",
        "\n",
        "# Split into training and test sets (80/20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, np.ravel(Y),\n",
        "    test_size=0.20,\n",
        "    random_state=42)"
      ],
      "metadata": {
        "id": "pRXjmHd3UZfZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
      ],
      "metadata": {
        "id": "QklElN14UQws"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Solver': [],\n",
        "    'Training Accuracy': [],\n",
        "    'Holdout Accuracy': [],\n",
        "    'Time Taken (seconds)': []\n",
        "}"
      ],
      "metadata": {
        "id": "0-Bbh-1fUU5r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in solvers:\n",
        "    start_time = time.time()\n",
        "\n",
        "    # For liblinear solver, we need to specify a valid penalty\n",
        "    if solver == 'liblinear':\n",
        "        clf = LogisticRegression(solver=solver, penalty='l2', random_state=42)\n",
        "    else:\n",
        "        clf = LogisticRegression(solver=solver, penalty=None, random_state=42)\n",
        "\n",
        "    # Fit the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate time taken\n",
        "    time_taken = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracies\n",
        "    train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "    # Store results\n",
        "    results['Solver'].append(solver)\n",
        "    results['Training Accuracy'].append(train_accuracy)\n",
        "    results['Holdout Accuracy'].append(test_accuracy)\n",
        "    results['Time Taken (seconds)'].append(time_taken)\n",
        "\n",
        "    print(f\"Completed solver: {solver}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzf9qNSnUWzr",
        "outputId": "2315efc2-ed6f-4d00-d127-4837d8ed2ac1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed solver: newton-cg\n",
            "Completed solver: lbfgs\n",
            "Completed solver: liblinear\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed solver: sag\n",
            "Completed solver: saga\n",
            "      Solver  Training Accuracy  Holdout Accuracy  Time Taken (seconds)\n",
            "0  newton-cg           0.748062           0.73550              0.475472\n",
            "1      lbfgs           0.747812           0.73575              0.515028\n",
            "2  liblinear           0.747938           0.73625              0.138068\n",
            "3        sag           0.748000           0.73600              1.825584\n",
            "4       saga           0.748437           0.73500              1.213396\n",
            "5  newton-cg           0.748062           0.73550              0.136485\n",
            "6      lbfgs           0.747812           0.73575              0.212048\n",
            "7  liblinear           0.747938           0.73625              0.141457\n",
            "8        sag           0.748000           0.73600              2.741828\n",
            "9       saga           0.748437           0.73500              4.063922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?**\n",
        "\n",
        "\n",
        "\n",
        "Multiple criteria should guide the solver ranking process because each metric provides distinct information about model performance. The liblinear solver demonstrates the most effective results when observing the three performance metrics as a whole. The model produced the highest holdout accuracy at 0.73625 which represents the essential real-world metric because it demonstrates how well the model performs on new data.\n",
        "The liblinear solver executed at a speed of 0.14 seconds which proved to be 3.5 times faster than newton-cg and lbfgs and more than 10 times faster than sag and saga solvers. The model's high computational speed proves crucial for handling big datasets and repeated model training operations.\n",
        "The saga solver achieved a slightly better training accuracy of 0.748437 but this minimal improvement did not translate to superior performance on the holdout set because the additional computational expense yields no meaningful generalization benefits. The holdout accuracy of saga ranked as the lowest among all solver tests.\n",
        "The sag and newton-cg solvers demonstrate average accuracy levels while their computational expenses differ. The sag solver displayed a convergence warning because it achieved the maximum iteration limit before reaching complete convergence which creates potential reliability issues.\n",
        "The liblinear solver emerges as the optimal selection for this logistic regression task because it achieves the most effective combination of accurate predictions on new data while maintaining efficient computation."
      ],
      "metadata": {
        "id": "JBrDUCmPUwAr"
      }
    }
  ]
}